{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LIN205_Custom_Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3rz_gmBeXr-",
        "colab_type": "text"
      },
      "source": [
        "# **This code is for training custom word embedding. Below is the original code (tutorial) I adapted from.**\n",
        "\n",
        "# The codes can be used in the jupyter notebook as well (with minimal adaptation)\n",
        "\n",
        "# Source:\n",
        "\n",
        "https://www.kaggle.com/chewzy/tutorial-how-to-train-your-custom-word-embedding\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8-WhXwAeX_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEIh5RsJt7n1",
        "colab_type": "text"
      },
      "source": [
        "# **Importing dataset**\n",
        "\n",
        "# After downloading the dataset (from /data folder), change path in order to load the file (for own use)\n",
        "\n",
        "# For training custom word embedding, chat.csv dataset (which consists of all conversations) is used. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d5enn_CiwBp",
        "colab_type": "code",
        "outputId": "ca6f629c-265c-4c1e-d1b8-9c4e76348ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# may need to change path for own use\n",
        "\n",
        "data = \"/content/drive/My Drive/Colab Notebooks/Colab Datasets/chat.csv\"\n",
        "data = pd.read_csv(data,encoding= 'unicode_escape')\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2343-chat_chatroom_bot_seeker-119-1</td>\n",
              "      <td>Hello!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2343-chat_chatroom_bot_seeker-119-1</td>\n",
              "      <td>Goode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2346-chat_chatroom_bot_seeker-120-1</td>\n",
              "      <td>hello</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2349-chat_chatroom_giver_seeker-152-1</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2349-chat_chatroom_giver_seeker-152-1</td>\n",
              "      <td>Hello</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 channel    body\n",
              "0    2343-chat_chatroom_bot_seeker-119-1  Hello!\n",
              "1    2343-chat_chatroom_bot_seeker-119-1   Goode\n",
              "2    2346-chat_chatroom_bot_seeker-120-1   hello\n",
              "3  2349-chat_chatroom_giver_seeker-152-1    Good\n",
              "4  2349-chat_chatroom_giver_seeker-152-1   Hello"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7XvOMKLus5R",
        "colab_type": "text"
      },
      "source": [
        "# **Spliting data into train (80%) and test (20%) datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_2ahmMvi_p1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['split'] = np.random.randn(data.shape[0], 1)\n",
        "\n",
        "msk = np.random.rand(len(data)) <= 0.8\n",
        "\n",
        "df_train = data[msk]\n",
        "df_test = data[~msk]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM9EkPnAuyvH",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbxFLgA0i-cG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(titles_array):\n",
        "    \n",
        "    \"\"\"\n",
        "    Take in an array of titles, and return the processed titles.\n",
        "    \n",
        "    (e.g. input: 'i am a boy', output - 'am boy')  -> since I remove those words with length 1\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    processed_array = []\n",
        "    \n",
        "    for title in tqdm(titles_array):\n",
        "        \n",
        "        # remove other non-alphabets symbols with space (i.e. keep only alphabets and whitespaces).\n",
        "        processed = re.sub('[^a-zA-Z ]', '', title)\n",
        "        \n",
        "        words = processed.split()\n",
        "        \n",
        "        # keep words that have length of more than 1 (e.g. gb, bb), remove those with length 1.\n",
        "        processed_array.append(' '.join([word for word in words if len(word) > 1]))\n",
        "    \n",
        "    return processed_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRJtC0mpkWCF",
        "colab_type": "code",
        "outputId": "6e41a055-f968-4aa1-8e4b-7ec81847890b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "df_train['processed'] = preprocessing(df_train['body'])\n",
        "df_test['processed'] = preprocessing(df_test['body'])\n",
        "\n",
        "sentences = pd.concat([df_train['processed'], df_test['processed']],axis=0)\n",
        "train_sentences = list(sentences.progress_apply(str.split).values)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 37531/37531 [00:00<00:00, 150961.03it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "100%|██████████| 9308/9308 [00:00<00:00, 157730.16it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "100%|██████████| 46839/46839 [00:00<00:00, 310434.63it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCTk43nkyTC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "732a6ff0-8e42-4674-f7ed-2b1c65eb3c8a"
      },
      "source": [
        "df_test.head()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel</th>\n",
              "      <th>body</th>\n",
              "      <th>split</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2343-chat_chatroom_bot_seeker-119-1</td>\n",
              "      <td>Hello!</td>\n",
              "      <td>0.477785</td>\n",
              "      <td>Hello</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2432-chat_chatroom_giver_seeker-153-1</td>\n",
              "      <td>is it because of school load?</td>\n",
              "      <td>-1.189789</td>\n",
              "      <td>is it because of school load</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2432-chat_chatroom_giver_seeker-153-1</td>\n",
              "      <td>I'm doing well. How are you?</td>\n",
              "      <td>2.026907</td>\n",
              "      <td>Im doing well How are you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2432-chat_chatroom_giver_seeker-153-1</td>\n",
              "      <td>I have one and that helps but she is still kin...</td>\n",
              "      <td>-0.080865</td>\n",
              "      <td>have one and that helps but she is still kinda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2432-chat_chatroom_giver_seeker-153-1</td>\n",
              "      <td>I have been like that my entire life though</td>\n",
              "      <td>-0.690493</td>\n",
              "      <td>have been like that my entire life though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  channel  ...                                          processed\n",
              "0     2343-chat_chatroom_bot_seeker-119-1  ...                                              Hello\n",
              "8   2432-chat_chatroom_giver_seeker-153-1  ...                       is it because of school load\n",
              "21  2432-chat_chatroom_giver_seeker-153-1  ...                          Im doing well How are you\n",
              "26  2432-chat_chatroom_giver_seeker-153-1  ...  have one and that helps but she is still kinda...\n",
              "28  2432-chat_chatroom_giver_seeker-153-1  ...          have been like that my entire life though\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-G0OB8vvDsw",
        "colab_type": "text"
      },
      "source": [
        "# **Customizing own embedding**\n",
        "\n",
        "# In my model, the following features/parameters are used.\n",
        "\n",
        "1) word2vec - skip-gram\n",
        "\n",
        "2) window = 5 (maximum distance between the current and predicted word within a sentence) \n",
        "\n",
        "3) min_count = 5 (ignore words with frequency lower than 5)\n",
        "\n",
        "4) size = 100 (dimensionality)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY9pgmpTknvE",
        "colab_type": "code",
        "outputId": "fbc3cd80-66ae-4a1e-fca7-f13a58319419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Parameters reference : https://radimrehurek.com/gensim/models/word2vec.html\n",
        "# https://blog.cambridgespark.com/tutorial-build-your-own-embedding-and-use-it-in-a-neural-network-e9cde4a81296\n",
        "# https://code.google.com/archive/p/word2vec/\n",
        "# https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
        "\n",
        "# Feel free to customise your own embedding\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "model = Word2Vec(sentences=train_sentences, \n",
        "                 sg=1, # 1 is skipgram, otherwise CBOW,\n",
        "                 window = 5, #maximum distance between the current and predicted word within a sentence\n",
        "                 min_count = 5, #ignore all words with total frequency lower than this\n",
        "                 size=100,  # size is dimensionality of the word vectors\n",
        "                 workers=8) # faster training with multicore machines (worker threads)\n",
        "\n",
        "print(f'Time taken : {(time.time() - start_time) / 60:.2f} mins')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken : 0.18 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJfkBElBkubU",
        "colab_type": "code",
        "outputId": "918f9f47-1793-440e-98e5-714e610269c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Total number of vocab in our custom word embedding\n",
        "\n",
        "len(model.wv.vocab.keys())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3410"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXK8XA2Gw5rK",
        "colab_type": "text"
      },
      "source": [
        "# Checking out the custom word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhTxJgPjkvVs",
        "colab_type": "code",
        "outputId": "052d9cff-d509-4c9d-ea34-4ece5b334962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check out the dimension of each word (we set it to 100 in the above training step)\n",
        "\n",
        "model.wv.vector_size"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky_xY6ikkzjS",
        "colab_type": "code",
        "outputId": "1e2972f5-d6bd-45c0-9e45-5a6b83bba8a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# Check out how 'help' is represented (an array of 100 numbers)\n",
        "\n",
        "# model.wv.get_vector()\n",
        "\n",
        "model.wv.get_vector('help')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.21495429, -0.50048214, -0.24143033, -0.34450617, -0.25399566,\n",
              "       -0.25645986, -0.07022206, -0.13176784,  0.00922605,  0.38232967,\n",
              "        0.27231622, -0.06061785, -0.19137514, -0.05118341, -0.68798375,\n",
              "       -0.44578826,  0.04183128,  0.15660809,  0.32332975,  0.04915569,\n",
              "        0.26782903,  0.85323566,  0.55630547, -0.01376082, -0.17712848,\n",
              "        0.17594993, -0.24976543, -0.10387248, -0.10015015,  0.12089061,\n",
              "        0.1234631 , -0.04847742,  0.4745364 , -0.07295658, -0.2096475 ,\n",
              "       -0.09335148,  0.43573454, -0.02736659,  0.22523093, -0.05802866,\n",
              "        0.45304695,  0.42329055,  0.05600791, -0.11216345, -0.39543858,\n",
              "       -0.32024956,  0.14385705, -0.8615967 , -0.13376516,  0.46861103,\n",
              "       -0.3354829 , -0.20952511,  0.52477056, -0.47828615, -0.33059335,\n",
              "       -0.13526139, -0.4701433 ,  0.4411752 ,  0.27758184, -0.137238  ,\n",
              "        0.76059896, -0.08159399, -0.55866456, -0.0097414 , -0.40151542,\n",
              "        0.39222232,  0.14563218,  0.0568664 ,  0.00285046, -0.64790756,\n",
              "       -0.41150463, -0.09939385,  0.10831063,  0.01438517,  0.4208088 ,\n",
              "        0.10908802, -0.22437175,  0.39049733, -0.40560427,  0.27595374,\n",
              "        0.28274217,  0.4545914 ,  0.00822997, -0.45698327, -0.07107864,\n",
              "       -0.34439328,  0.00096209,  0.13727278, -0.24949841,  0.0165299 ,\n",
              "       -0.27382994, -0.27036825, -0.00164719,  0.2016023 ,  0.12666029,\n",
              "        0.19202428, -0.18801892, -0.14556186,  0.09186716,  0.46340644],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Yz2rXPZU2k",
        "colab_type": "code",
        "outputId": "8320c1b4-5175-4a51-e908-a92696bef422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "word_vectors = model.wv\n",
        "result = word_vectors.similar_by_word(\"not\")\n",
        "print(result[:3])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Not', 0.5344575643539429), ('Fair', 0.5196408033370972), ('doesnt', 0.4999895989894867)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFv16Otfaf3C",
        "colab_type": "code",
        "outputId": "459341fb-bc96-40c0-a15e-ea99806a16de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "result = word_vectors.most_similar(positive = [\"charity\"], negative = ['person'])\n",
        "print(\"Most similar to 'charity' but dissimilar to 'person':\\n\", result[:3])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most similar to 'charity' but dissimilar to 'person':\n",
            " [('organization', 0.4008829593658447), ('foundation', 0.37110769748687744), ('Charity', 0.31258493661880493)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnaP_hovfuiS",
        "colab_type": "code",
        "outputId": "e79ab1c8-5302-4b3a-ffb2-c9e70a7d0a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "result = word_vectors.most_similar(positive=['children', 'charity'], negative=['money'], topn=1)\n",
        "print(result)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('organization', 0.5570844411849976)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsqCYQeEagZ7",
        "colab_type": "text"
      },
      "source": [
        "# **Save the model to a specific path**\n",
        "\n",
        "The path & filename can be changed "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aduVxxIlIrj",
        "colab_type": "code",
        "outputId": "09de9ffa-691b-4fa6-bb55-d547c1567c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# may need to change path for own use\n",
        "\n",
        "model.wv.save_word2vec_format('/content/drive/My Drive/Colab Notebooks/Colab Datasets/custom_glove_100d.txt')\n",
        "\n",
        "# How to load:\n",
        "# w2v = KeyedVectors.load_word2vec_format('custom_glove_100d_1.txt')\n",
        "\n",
        "# How to get vector using loaded model\n",
        "# w2v.get_vector('iphone')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}